{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_data = pd.read_excel(\"data/cases_2021_train_processed_2.xlsx\")\n",
    "test_data = pd.read_excel(\"data/cases_2021_test_processed_unlabelled_2.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.copy()\n",
    "train = train[['age', 'country', 'chronic_disease_binary', 'Case_Fatality_Ratio','outcome_group']]\n",
    "test = test_data.copy()\n",
    "test = test[['age', 'country', 'chronic_disease_binary', 'Case_Fatality_Ratio']]\n",
    "train_data, test_data = train,test "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Feature Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.copy()\n",
    "train['country'] = pd.factorize(train['country'])[0]\n",
    "train['chronic_disease_binary'] = pd.factorize(train['chronic_disease_binary'])[0]\n",
    "new_label = {\"outcome_group\": {\"deceased\": 0, \"hospitalized\": 1, \"nonhospitalized\": 2}}\n",
    "train.replace(new_label, inplace = True)\n",
    "test = test_data.copy()\n",
    "test['country'] = pd.factorize(test['country'])[0]\n",
    "test['chronic_disease_binary'] = pd.factorize(test['chronic_disease_binary'])[0]\n",
    "train_data, test_data = train,test "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Balancing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before Balancing,\n",
      "outcome_group\n",
      "0      997\n",
      "1    13241\n",
      "2     2974\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Balancing,\n",
      "outcome_group\n",
      "0     9970\n",
      "1    10569\n",
      "2     9814\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_train_dataset_pie_chart(train_dataset: pd.DataFrame, title: str):\n",
    "    plt.figure()\n",
    "    data = train_dataset.groupby(\"outcome_group\").size()\n",
    "    print(\"\\n\" + title + \",\")\n",
    "    print(data)\n",
    "    data = [int(data[0]), int(data[1]), int(data[2])]\n",
    "    labels = [\"deceased\", \"hospitalized\", \"nonhospitalized\"]\n",
    "    colours = sns.color_palette('pastel')[0:4]\n",
    "    plt.pie(x=data, labels=labels, colors=colours, autopct='%.0f%%')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "show_train_dataset_pie_chart(train_data, \"Before Balancing\")\n",
    "\n",
    "deceased = train_data[train_data[\"outcome_group\"] == 0]\n",
    "new_deceased = deceased.sample(frac=10, replace=True, random_state=1)\n",
    "new_deceased.reset_index(inplace=True, drop=True)\n",
    "\n",
    "hospitalized = train_data[train_data[\"outcome_group\"] == 1]\n",
    "hospitalized_sample = np.random.choice(hospitalized.index, 3000, replace=True)\n",
    "new_hospitalized = hospitalized.drop(hospitalized_sample)\n",
    "new_hospitalized.reset_index(inplace=True, drop=True)\n",
    "\n",
    "nonhospitalized = train_data[train_data[\"outcome_group\"] == 2]\n",
    "new_nonhospitalized = nonhospitalized.sample(frac=3.3, replace=True, random_state=1)\n",
    "new_nonhospitalized.reset_index(inplace=True, drop=True)\n",
    "\n",
    "new_train = pd.concat([new_deceased, new_hospitalized, new_nonhospitalized])\n",
    "new_train.sort_index(axis = 0, inplace=True)\n",
    "new_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "show_train_dataset_pie_chart(new_train, \"After Balancing\")\n",
    "\n",
    "train_data = new_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Building Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation Split,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(train_data, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.814 total time=   0.5s\n",
      "[CV 2/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.809 total time=   0.5s\n",
      "[CV 3/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.814 total time=   0.5s\n",
      "[CV 4/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.809 total time=   0.5s\n",
      "[CV 5/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.801 total time=   0.6s\n",
      "[CV 1/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.814 total time=   0.9s\n",
      "[CV 2/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.809 total time=   0.9s\n",
      "[CV 3/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.816 total time=   0.9s\n",
      "[CV 4/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.809 total time=   1.0s\n",
      "[CV 5/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.804 total time=   0.9s\n",
      "[CV 1/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.814 total time=   0.7s\n",
      "[CV 2/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.811 total time=   0.7s\n",
      "[CV 3/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.816 total time=   0.8s\n",
      "[CV 4/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.811 total time=   0.7s\n",
      "[CV 5/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.803 total time=   0.7s\n",
      "[CV 1/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.814 total time=   1.3s\n",
      "[CV 2/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.812 total time=   1.3s\n",
      "[CV 3/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.818 total time=   1.3s\n",
      "[CV 4/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.811 total time=   1.3s\n",
      "[CV 5/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.804 total time=   1.3s\n",
      "[CV 1/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.816 total time=   0.9s\n",
      "[CV 2/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.810 total time=   0.9s\n",
      "[CV 3/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.818 total time=   0.9s\n",
      "[CV 4/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.0s\n",
      "[CV 5/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.806 total time=   0.9s\n",
      "[CV 1/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.815 total time=   1.6s\n",
      "[CV 2/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.807 total time=   1.6s\n",
      "[CV 3/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.818 total time=   1.6s\n",
      "[CV 4/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.6s\n",
      "[CV 5/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.806 total time=   1.6s\n",
      "[CV 1/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.814 total time=   0.5s\n",
      "[CV 2/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.809 total time=   0.5s\n",
      "[CV 3/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.816 total time=   0.6s\n",
      "[CV 4/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.810 total time=   0.5s\n",
      "[CV 5/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.803 total time=   0.6s\n",
      "[CV 1/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.815 total time=   0.9s\n",
      "[CV 2/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.0s\n",
      "[CV 3/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.817 total time=   1.0s\n",
      "[CV 4/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.0s\n",
      "[CV 5/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.805 total time=   0.9s\n",
      "[CV 1/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.815 total time=   0.7s\n",
      "[CV 2/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.811 total time=   0.7s\n",
      "[CV 3/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.818 total time=   0.7s\n",
      "[CV 4/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.810 total time=   0.7s\n",
      "[CV 5/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.805 total time=   0.7s\n",
      "[CV 1/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.815 total time=   1.3s\n",
      "[CV 2/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.808 total time=   1.3s\n",
      "[CV 3/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.818 total time=   1.3s\n",
      "[CV 4/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.811 total time=   1.3s\n",
      "[CV 5/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.806 total time=   1.3s\n",
      "[CV 1/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.815 total time=   1.0s\n",
      "[CV 2/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.807 total time=   1.0s\n",
      "[CV 3/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.818 total time=   0.9s\n",
      "[CV 4/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.810 total time=   0.9s\n",
      "[CV 5/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.805 total time=   0.9s\n",
      "[CV 1/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.815 total time=   1.6s\n",
      "[CV 2/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.808 total time=   1.6s\n",
      "[CV 3/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.818 total time=   1.6s\n",
      "[CV 4/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.6s\n",
      "[CV 5/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.806 total time=   1.6s\n",
      "XG Boost GridSearchCV best score = 0.8120449396114404\n",
      "XG Boost GridSearchCV best parameters = {'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 150, 'num_class': 3, 'objective': 'multi:softmax'}\n",
      "XG Boost GridSearchCV deceased class f1-score = 0.7353996737357259\n",
      "XG Boost GridSearchCV accuracy score = 0.8261712306169581\n"
     ]
    }
   ],
   "source": [
    "# Takes about 1 - 2 minutes to run.\n",
    "\n",
    "# Decide number of k-fold splits\n",
    "k = 5\n",
    "# Create model with blank parameters\n",
    "xgb_model = xgb.XGBClassifier(random_state = 1)\n",
    "# Create space of possible parameters\n",
    "parameter_search_space = {\n",
    "    \"learning_rate\": [0.2, 0.3],\n",
    "    \"max_depth\": [6, 8, 10],\n",
    "    \"n_estimators\": [150, 250],\n",
    "    \"objective\": [\"multi:softmax\"],\n",
    "    \"num_class\": [3]\n",
    "}\n",
    "# Create grid search cross validation object\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=parameter_search_space,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=k,\n",
    "    verbose=10\n",
    ")\n",
    "# Put data and labels in proper format\n",
    "data = train_data.iloc[:, :4].values\n",
    "labels = train_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "# Fit grid search object\n",
    "grid_search_cv.fit(data, labels)\n",
    "# Print and save results.\n",
    "print(\"XG Boost GridSearchCV best score = \" + str(grid_search_cv.best_score_))\n",
    "print(\"XG Boost GridSearchCV best parameters = \" + str(grid_search_cv.best_params_))\n",
    "predictions = grid_search_cv.predict(data)\n",
    "_, _, fscore, _ = precision_recall_fscore_support(predictions, labels)\n",
    "print(\"XG Boost GridSearchCV deceased class f1-score = \" + str(fscore[0]))\n",
    "accuracy = accuracy_score(predictions, labels)\n",
    "print(\"XG Boost GridSearchCV accuracy score = \" + str(accuracy))\n",
    "pd.DataFrame(grid_search_cv.cv_results_).to_csv(\"xgboost_results.csv\")\n",
    "xgb_model = grid_search_cv.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5; 1/32] START criterion=gini, max_features=1, n_estimators=50............\n",
      "[CV 1/5; 1/32] END criterion=gini, max_features=1, n_estimators=50;, score=0.816 total time=   0.2s\n",
      "[CV 2/5; 1/32] START criterion=gini, max_features=1, n_estimators=50............\n",
      "[CV 2/5; 1/32] END criterion=gini, max_features=1, n_estimators=50;, score=0.808 total time=   0.2s\n",
      "[CV 3/5; 1/32] START criterion=gini, max_features=1, n_estimators=50............\n",
      "[CV 3/5; 1/32] END criterion=gini, max_features=1, n_estimators=50;, score=0.819 total time=   0.2s\n",
      "[CV 4/5; 1/32] START criterion=gini, max_features=1, n_estimators=50............\n",
      "[CV 4/5; 1/32] END criterion=gini, max_features=1, n_estimators=50;, score=0.811 total time=   0.2s\n",
      "[CV 5/5; 1/32] START criterion=gini, max_features=1, n_estimators=50............\n",
      "[CV 5/5; 1/32] END criterion=gini, max_features=1, n_estimators=50;, score=0.805 total time=   0.2s\n",
      "[CV 1/5; 2/32] START criterion=gini, max_features=1, n_estimators=100...........\n",
      "[CV 1/5; 2/32] END criterion=gini, max_features=1, n_estimators=100;, score=0.815 total time=   0.5s\n",
      "[CV 2/5; 2/32] START criterion=gini, max_features=1, n_estimators=100...........\n",
      "[CV 2/5; 2/32] END criterion=gini, max_features=1, n_estimators=100;, score=0.807 total time=   0.5s\n",
      "[CV 3/5; 2/32] START criterion=gini, max_features=1, n_estimators=100...........\n",
      "[CV 3/5; 2/32] END criterion=gini, max_features=1, n_estimators=100;, score=0.817 total time=   0.5s\n",
      "[CV 4/5; 2/32] START criterion=gini, max_features=1, n_estimators=100...........\n",
      "[CV 4/5; 2/32] END criterion=gini, max_features=1, n_estimators=100;, score=0.811 total time=   0.5s\n",
      "[CV 5/5; 2/32] START criterion=gini, max_features=1, n_estimators=100...........\n",
      "[CV 5/5; 2/32] END criterion=gini, max_features=1, n_estimators=100;, score=0.805 total time=   0.5s\n",
      "[CV 1/5; 3/32] START criterion=gini, max_features=1, n_estimators=150...........\n",
      "[CV 1/5; 3/32] END criterion=gini, max_features=1, n_estimators=150;, score=0.815 total time=   0.8s\n",
      "[CV 2/5; 3/32] START criterion=gini, max_features=1, n_estimators=150...........\n",
      "[CV 2/5; 3/32] END criterion=gini, max_features=1, n_estimators=150;, score=0.808 total time=   0.8s\n",
      "[CV 3/5; 3/32] START criterion=gini, max_features=1, n_estimators=150...........\n",
      "[CV 3/5; 3/32] END criterion=gini, max_features=1, n_estimators=150;, score=0.819 total time=   0.8s\n",
      "[CV 4/5; 3/32] START criterion=gini, max_features=1, n_estimators=150...........\n",
      "[CV 4/5; 3/32] END criterion=gini, max_features=1, n_estimators=150;, score=0.811 total time=   0.8s\n",
      "[CV 5/5; 3/32] START criterion=gini, max_features=1, n_estimators=150...........\n",
      "[CV 5/5; 3/32] END criterion=gini, max_features=1, n_estimators=150;, score=0.805 total time=   0.8s\n",
      "[CV 1/5; 4/32] START criterion=gini, max_features=1, n_estimators=200...........\n",
      "[CV 1/5; 4/32] END criterion=gini, max_features=1, n_estimators=200;, score=0.816 total time=   1.1s\n",
      "[CV 2/5; 4/32] START criterion=gini, max_features=1, n_estimators=200...........\n",
      "[CV 2/5; 4/32] END criterion=gini, max_features=1, n_estimators=200;, score=0.807 total time=   1.1s\n",
      "[CV 3/5; 4/32] START criterion=gini, max_features=1, n_estimators=200...........\n",
      "[CV 3/5; 4/32] END criterion=gini, max_features=1, n_estimators=200;, score=0.820 total time=   1.1s\n",
      "[CV 4/5; 4/32] START criterion=gini, max_features=1, n_estimators=200...........\n",
      "[CV 4/5; 4/32] END criterion=gini, max_features=1, n_estimators=200;, score=0.810 total time=   1.1s\n",
      "[CV 5/5; 4/32] START criterion=gini, max_features=1, n_estimators=200...........\n",
      "[CV 5/5; 4/32] END criterion=gini, max_features=1, n_estimators=200;, score=0.805 total time=   1.1s\n",
      "[CV 1/5; 5/32] START criterion=gini, max_features=2, n_estimators=50............\n",
      "[CV 1/5; 5/32] END criterion=gini, max_features=2, n_estimators=50;, score=0.816 total time=   0.2s\n",
      "[CV 2/5; 5/32] START criterion=gini, max_features=2, n_estimators=50............\n",
      "[CV 2/5; 5/32] END criterion=gini, max_features=2, n_estimators=50;, score=0.807 total time=   0.2s\n",
      "[CV 3/5; 5/32] START criterion=gini, max_features=2, n_estimators=50............\n",
      "[CV 3/5; 5/32] END criterion=gini, max_features=2, n_estimators=50;, score=0.818 total time=   0.2s\n",
      "[CV 4/5; 5/32] START criterion=gini, max_features=2, n_estimators=50............\n",
      "[CV 4/5; 5/32] END criterion=gini, max_features=2, n_estimators=50;, score=0.811 total time=   0.2s\n",
      "[CV 5/5; 5/32] START criterion=gini, max_features=2, n_estimators=50............\n",
      "[CV 5/5; 5/32] END criterion=gini, max_features=2, n_estimators=50;, score=0.805 total time=   0.2s\n",
      "[CV 1/5; 6/32] START criterion=gini, max_features=2, n_estimators=100...........\n",
      "[CV 1/5; 6/32] END criterion=gini, max_features=2, n_estimators=100;, score=0.815 total time=   0.6s\n",
      "[CV 2/5; 6/32] START criterion=gini, max_features=2, n_estimators=100...........\n",
      "[CV 2/5; 6/32] END criterion=gini, max_features=2, n_estimators=100;, score=0.807 total time=   0.6s\n",
      "[CV 3/5; 6/32] START criterion=gini, max_features=2, n_estimators=100...........\n",
      "[CV 3/5; 6/32] END criterion=gini, max_features=2, n_estimators=100;, score=0.817 total time=   0.6s\n",
      "[CV 4/5; 6/32] START criterion=gini, max_features=2, n_estimators=100...........\n",
      "[CV 4/5; 6/32] END criterion=gini, max_features=2, n_estimators=100;, score=0.811 total time=   0.5s\n",
      "[CV 5/5; 6/32] START criterion=gini, max_features=2, n_estimators=100...........\n",
      "[CV 5/5; 6/32] END criterion=gini, max_features=2, n_estimators=100;, score=0.805 total time=   0.6s\n",
      "[CV 1/5; 7/32] START criterion=gini, max_features=2, n_estimators=150...........\n",
      "[CV 1/5; 7/32] END criterion=gini, max_features=2, n_estimators=150;, score=0.815 total time=   0.9s\n",
      "[CV 2/5; 7/32] START criterion=gini, max_features=2, n_estimators=150...........\n",
      "[CV 2/5; 7/32] END criterion=gini, max_features=2, n_estimators=150;, score=0.808 total time=   0.9s\n",
      "[CV 3/5; 7/32] START criterion=gini, max_features=2, n_estimators=150...........\n",
      "[CV 3/5; 7/32] END criterion=gini, max_features=2, n_estimators=150;, score=0.819 total time=   0.9s\n",
      "[CV 4/5; 7/32] START criterion=gini, max_features=2, n_estimators=150...........\n",
      "[CV 4/5; 7/32] END criterion=gini, max_features=2, n_estimators=150;, score=0.811 total time=   0.9s\n",
      "[CV 5/5; 7/32] START criterion=gini, max_features=2, n_estimators=150...........\n",
      "[CV 5/5; 7/32] END criterion=gini, max_features=2, n_estimators=150;, score=0.805 total time=   0.9s\n",
      "[CV 1/5; 8/32] START criterion=gini, max_features=2, n_estimators=200...........\n",
      "[CV 1/5; 8/32] END criterion=gini, max_features=2, n_estimators=200;, score=0.816 total time=   1.2s\n",
      "[CV 2/5; 8/32] START criterion=gini, max_features=2, n_estimators=200...........\n",
      "[CV 2/5; 8/32] END criterion=gini, max_features=2, n_estimators=200;, score=0.807 total time=   1.2s\n",
      "[CV 3/5; 8/32] START criterion=gini, max_features=2, n_estimators=200...........\n",
      "[CV 3/5; 8/32] END criterion=gini, max_features=2, n_estimators=200;, score=0.819 total time=   1.3s\n",
      "[CV 4/5; 8/32] START criterion=gini, max_features=2, n_estimators=200...........\n",
      "[CV 4/5; 8/32] END criterion=gini, max_features=2, n_estimators=200;, score=0.811 total time=   1.3s\n",
      "[CV 5/5; 8/32] START criterion=gini, max_features=2, n_estimators=200...........\n",
      "[CV 5/5; 8/32] END criterion=gini, max_features=2, n_estimators=200;, score=0.805 total time=   1.2s\n",
      "[CV 1/5; 9/32] START criterion=gini, max_features=3, n_estimators=50............\n",
      "[CV 1/5; 9/32] END criterion=gini, max_features=3, n_estimators=50;, score=0.816 total time=   0.3s\n",
      "[CV 2/5; 9/32] START criterion=gini, max_features=3, n_estimators=50............\n",
      "[CV 2/5; 9/32] END criterion=gini, max_features=3, n_estimators=50;, score=0.807 total time=   0.3s\n",
      "[CV 3/5; 9/32] START criterion=gini, max_features=3, n_estimators=50............\n",
      "[CV 3/5; 9/32] END criterion=gini, max_features=3, n_estimators=50;, score=0.819 total time=   0.3s\n",
      "[CV 4/5; 9/32] START criterion=gini, max_features=3, n_estimators=50............\n",
      "[CV 4/5; 9/32] END criterion=gini, max_features=3, n_estimators=50;, score=0.811 total time=   0.3s\n",
      "[CV 5/5; 9/32] START criterion=gini, max_features=3, n_estimators=50............\n",
      "[CV 5/5; 9/32] END criterion=gini, max_features=3, n_estimators=50;, score=0.804 total time=   0.3s\n",
      "[CV 1/5; 10/32] START criterion=gini, max_features=3, n_estimators=100..........\n",
      "[CV 1/5; 10/32] END criterion=gini, max_features=3, n_estimators=100;, score=0.815 total time=   0.7s\n",
      "[CV 2/5; 10/32] START criterion=gini, max_features=3, n_estimators=100..........\n",
      "[CV 2/5; 10/32] END criterion=gini, max_features=3, n_estimators=100;, score=0.806 total time=   0.6s\n",
      "[CV 3/5; 10/32] START criterion=gini, max_features=3, n_estimators=100..........\n",
      "[CV 3/5; 10/32] END criterion=gini, max_features=3, n_estimators=100;, score=0.817 total time=   0.7s\n",
      "[CV 4/5; 10/32] START criterion=gini, max_features=3, n_estimators=100..........\n",
      "[CV 4/5; 10/32] END criterion=gini, max_features=3, n_estimators=100;, score=0.811 total time=   0.7s\n",
      "[CV 5/5; 10/32] START criterion=gini, max_features=3, n_estimators=100..........\n",
      "[CV 5/5; 10/32] END criterion=gini, max_features=3, n_estimators=100;, score=0.804 total time=   0.7s\n",
      "[CV 1/5; 11/32] START criterion=gini, max_features=3, n_estimators=150..........\n",
      "[CV 1/5; 11/32] END criterion=gini, max_features=3, n_estimators=150;, score=0.815 total time=   1.0s\n",
      "[CV 2/5; 11/32] START criterion=gini, max_features=3, n_estimators=150..........\n",
      "[CV 2/5; 11/32] END criterion=gini, max_features=3, n_estimators=150;, score=0.807 total time=   1.0s\n",
      "[CV 3/5; 11/32] START criterion=gini, max_features=3, n_estimators=150..........\n",
      "[CV 3/5; 11/32] END criterion=gini, max_features=3, n_estimators=150;, score=0.819 total time=   1.0s\n",
      "[CV 4/5; 11/32] START criterion=gini, max_features=3, n_estimators=150..........\n",
      "[CV 4/5; 11/32] END criterion=gini, max_features=3, n_estimators=150;, score=0.811 total time=   1.0s\n",
      "[CV 5/5; 11/32] START criterion=gini, max_features=3, n_estimators=150..........\n",
      "[CV 5/5; 11/32] END criterion=gini, max_features=3, n_estimators=150;, score=0.804 total time=   1.0s\n",
      "[CV 1/5; 12/32] START criterion=gini, max_features=3, n_estimators=200..........\n",
      "[CV 1/5; 12/32] END criterion=gini, max_features=3, n_estimators=200;, score=0.816 total time=   1.3s\n",
      "[CV 2/5; 12/32] START criterion=gini, max_features=3, n_estimators=200..........\n",
      "[CV 2/5; 12/32] END criterion=gini, max_features=3, n_estimators=200;, score=0.807 total time=   1.3s\n",
      "[CV 3/5; 12/32] START criterion=gini, max_features=3, n_estimators=200..........\n",
      "[CV 3/5; 12/32] END criterion=gini, max_features=3, n_estimators=200;, score=0.819 total time=   1.3s\n",
      "[CV 4/5; 12/32] START criterion=gini, max_features=3, n_estimators=200..........\n",
      "[CV 4/5; 12/32] END criterion=gini, max_features=3, n_estimators=200;, score=0.810 total time=   1.3s\n",
      "[CV 5/5; 12/32] START criterion=gini, max_features=3, n_estimators=200..........\n",
      "[CV 5/5; 12/32] END criterion=gini, max_features=3, n_estimators=200;, score=0.805 total time=   1.3s\n",
      "[CV 1/5; 13/32] START criterion=gini, max_features=4, n_estimators=50...........\n",
      "[CV 1/5; 13/32] END criterion=gini, max_features=4, n_estimators=50;, score=0.816 total time=   0.3s\n",
      "[CV 2/5; 13/32] START criterion=gini, max_features=4, n_estimators=50...........\n",
      "[CV 2/5; 13/32] END criterion=gini, max_features=4, n_estimators=50;, score=0.806 total time=   0.3s\n",
      "[CV 3/5; 13/32] START criterion=gini, max_features=4, n_estimators=50...........\n",
      "[CV 3/5; 13/32] END criterion=gini, max_features=4, n_estimators=50;, score=0.818 total time=   0.3s\n",
      "[CV 4/5; 13/32] START criterion=gini, max_features=4, n_estimators=50...........\n",
      "[CV 4/5; 13/32] END criterion=gini, max_features=4, n_estimators=50;, score=0.811 total time=   0.3s\n",
      "[CV 5/5; 13/32] START criterion=gini, max_features=4, n_estimators=50...........\n",
      "[CV 5/5; 13/32] END criterion=gini, max_features=4, n_estimators=50;, score=0.804 total time=   0.3s\n",
      "[CV 1/5; 14/32] START criterion=gini, max_features=4, n_estimators=100..........\n",
      "[CV 1/5; 14/32] END criterion=gini, max_features=4, n_estimators=100;, score=0.816 total time=   0.7s\n",
      "[CV 2/5; 14/32] START criterion=gini, max_features=4, n_estimators=100..........\n",
      "[CV 2/5; 14/32] END criterion=gini, max_features=4, n_estimators=100;, score=0.806 total time=   0.7s\n",
      "[CV 3/5; 14/32] START criterion=gini, max_features=4, n_estimators=100..........\n",
      "[CV 3/5; 14/32] END criterion=gini, max_features=4, n_estimators=100;, score=0.817 total time=   0.7s\n",
      "[CV 4/5; 14/32] START criterion=gini, max_features=4, n_estimators=100..........\n",
      "[CV 4/5; 14/32] END criterion=gini, max_features=4, n_estimators=100;, score=0.811 total time=   0.7s\n",
      "[CV 5/5; 14/32] START criterion=gini, max_features=4, n_estimators=100..........\n",
      "[CV 5/5; 14/32] END criterion=gini, max_features=4, n_estimators=100;, score=0.804 total time=   0.7s\n",
      "[CV 1/5; 15/32] START criterion=gini, max_features=4, n_estimators=150..........\n",
      "[CV 1/5; 15/32] END criterion=gini, max_features=4, n_estimators=150;, score=0.816 total time=   1.1s\n",
      "[CV 2/5; 15/32] START criterion=gini, max_features=4, n_estimators=150..........\n",
      "[CV 2/5; 15/32] END criterion=gini, max_features=4, n_estimators=150;, score=0.807 total time=   1.1s\n",
      "[CV 3/5; 15/32] START criterion=gini, max_features=4, n_estimators=150..........\n",
      "[CV 3/5; 15/32] END criterion=gini, max_features=4, n_estimators=150;, score=0.819 total time=   1.1s\n",
      "[CV 4/5; 15/32] START criterion=gini, max_features=4, n_estimators=150..........\n",
      "[CV 4/5; 15/32] END criterion=gini, max_features=4, n_estimators=150;, score=0.811 total time=   1.1s\n",
      "[CV 5/5; 15/32] START criterion=gini, max_features=4, n_estimators=150..........\n",
      "[CV 5/5; 15/32] END criterion=gini, max_features=4, n_estimators=150;, score=0.804 total time=   1.1s\n",
      "[CV 1/5; 16/32] START criterion=gini, max_features=4, n_estimators=200..........\n",
      "[CV 1/5; 16/32] END criterion=gini, max_features=4, n_estimators=200;, score=0.816 total time=   1.5s\n",
      "[CV 2/5; 16/32] START criterion=gini, max_features=4, n_estimators=200..........\n",
      "[CV 2/5; 16/32] END criterion=gini, max_features=4, n_estimators=200;, score=0.806 total time=   1.5s\n",
      "[CV 3/5; 16/32] START criterion=gini, max_features=4, n_estimators=200..........\n",
      "[CV 3/5; 16/32] END criterion=gini, max_features=4, n_estimators=200;, score=0.819 total time=   1.5s\n",
      "[CV 4/5; 16/32] START criterion=gini, max_features=4, n_estimators=200..........\n",
      "[CV 4/5; 16/32] END criterion=gini, max_features=4, n_estimators=200;, score=0.811 total time=   1.5s\n",
      "[CV 5/5; 16/32] START criterion=gini, max_features=4, n_estimators=200..........\n",
      "[CV 5/5; 16/32] END criterion=gini, max_features=4, n_estimators=200;, score=0.804 total time=   1.5s\n",
      "[CV 1/5; 17/32] START criterion=entropy, max_features=1, n_estimators=50........\n",
      "[CV 1/5; 17/32] END criterion=entropy, max_features=1, n_estimators=50;, score=0.816 total time=   0.2s\n",
      "[CV 2/5; 17/32] START criterion=entropy, max_features=1, n_estimators=50........\n",
      "[CV 2/5; 17/32] END criterion=entropy, max_features=1, n_estimators=50;, score=0.808 total time=   0.2s\n",
      "[CV 3/5; 17/32] START criterion=entropy, max_features=1, n_estimators=50........\n",
      "[CV 3/5; 17/32] END criterion=entropy, max_features=1, n_estimators=50;, score=0.819 total time=   0.2s\n",
      "[CV 4/5; 17/32] START criterion=entropy, max_features=1, n_estimators=50........\n",
      "[CV 4/5; 17/32] END criterion=entropy, max_features=1, n_estimators=50;, score=0.812 total time=   0.2s\n",
      "[CV 5/5; 17/32] START criterion=entropy, max_features=1, n_estimators=50........\n",
      "[CV 5/5; 17/32] END criterion=entropy, max_features=1, n_estimators=50;, score=0.805 total time=   0.2s\n",
      "[CV 1/5; 18/32] START criterion=entropy, max_features=1, n_estimators=100.......\n",
      "[CV 1/5; 18/32] END criterion=entropy, max_features=1, n_estimators=100;, score=0.816 total time=   0.5s\n",
      "[CV 2/5; 18/32] START criterion=entropy, max_features=1, n_estimators=100.......\n",
      "[CV 2/5; 18/32] END criterion=entropy, max_features=1, n_estimators=100;, score=0.808 total time=   0.5s\n",
      "[CV 3/5; 18/32] START criterion=entropy, max_features=1, n_estimators=100.......\n",
      "[CV 3/5; 18/32] END criterion=entropy, max_features=1, n_estimators=100;, score=0.818 total time=   0.5s\n",
      "[CV 4/5; 18/32] START criterion=entropy, max_features=1, n_estimators=100.......\n",
      "[CV 4/5; 18/32] END criterion=entropy, max_features=1, n_estimators=100;, score=0.811 total time=   0.5s\n",
      "[CV 5/5; 18/32] START criterion=entropy, max_features=1, n_estimators=100.......\n",
      "[CV 5/5; 18/32] END criterion=entropy, max_features=1, n_estimators=100;, score=0.805 total time=   0.5s\n",
      "[CV 1/5; 19/32] START criterion=entropy, max_features=1, n_estimators=150.......\n",
      "[CV 1/5; 19/32] END criterion=entropy, max_features=1, n_estimators=150;, score=0.816 total time=   0.8s\n",
      "[CV 2/5; 19/32] START criterion=entropy, max_features=1, n_estimators=150.......\n",
      "[CV 2/5; 19/32] END criterion=entropy, max_features=1, n_estimators=150;, score=0.808 total time=   0.8s\n",
      "[CV 3/5; 19/32] START criterion=entropy, max_features=1, n_estimators=150.......\n",
      "[CV 3/5; 19/32] END criterion=entropy, max_features=1, n_estimators=150;, score=0.819 total time=   0.8s\n",
      "[CV 4/5; 19/32] START criterion=entropy, max_features=1, n_estimators=150.......\n",
      "[CV 4/5; 19/32] END criterion=entropy, max_features=1, n_estimators=150;, score=0.811 total time=   0.8s\n",
      "[CV 5/5; 19/32] START criterion=entropy, max_features=1, n_estimators=150.......\n",
      "[CV 5/5; 19/32] END criterion=entropy, max_features=1, n_estimators=150;, score=0.805 total time=   0.8s\n",
      "[CV 1/5; 20/32] START criterion=entropy, max_features=1, n_estimators=200.......\n",
      "[CV 1/5; 20/32] END criterion=entropy, max_features=1, n_estimators=200;, score=0.816 total time=   1.1s\n",
      "[CV 2/5; 20/32] START criterion=entropy, max_features=1, n_estimators=200.......\n",
      "[CV 2/5; 20/32] END criterion=entropy, max_features=1, n_estimators=200;, score=0.807 total time=   1.1s\n",
      "[CV 3/5; 20/32] START criterion=entropy, max_features=1, n_estimators=200.......\n",
      "[CV 3/5; 20/32] END criterion=entropy, max_features=1, n_estimators=200;, score=0.819 total time=   1.1s\n",
      "[CV 4/5; 20/32] START criterion=entropy, max_features=1, n_estimators=200.......\n",
      "[CV 4/5; 20/32] END criterion=entropy, max_features=1, n_estimators=200;, score=0.810 total time=   1.1s\n",
      "[CV 5/5; 20/32] START criterion=entropy, max_features=1, n_estimators=200.......\n",
      "[CV 5/5; 20/32] END criterion=entropy, max_features=1, n_estimators=200;, score=0.806 total time=   1.1s\n",
      "[CV 1/5; 21/32] START criterion=entropy, max_features=2, n_estimators=50........\n",
      "[CV 1/5; 21/32] END criterion=entropy, max_features=2, n_estimators=50;, score=0.816 total time=   0.2s\n",
      "[CV 2/5; 21/32] START criterion=entropy, max_features=2, n_estimators=50........\n",
      "[CV 2/5; 21/32] END criterion=entropy, max_features=2, n_estimators=50;, score=0.808 total time=   0.2s\n",
      "[CV 3/5; 21/32] START criterion=entropy, max_features=2, n_estimators=50........\n",
      "[CV 3/5; 21/32] END criterion=entropy, max_features=2, n_estimators=50;, score=0.819 total time=   0.2s\n",
      "[CV 4/5; 21/32] START criterion=entropy, max_features=2, n_estimators=50........\n",
      "[CV 4/5; 21/32] END criterion=entropy, max_features=2, n_estimators=50;, score=0.811 total time=   0.2s\n",
      "[CV 5/5; 21/32] START criterion=entropy, max_features=2, n_estimators=50........\n",
      "[CV 5/5; 21/32] END criterion=entropy, max_features=2, n_estimators=50;, score=0.804 total time=   0.2s\n",
      "[CV 1/5; 22/32] START criterion=entropy, max_features=2, n_estimators=100.......\n",
      "[CV 1/5; 22/32] END criterion=entropy, max_features=2, n_estimators=100;, score=0.816 total time=   0.6s\n",
      "[CV 2/5; 22/32] START criterion=entropy, max_features=2, n_estimators=100.......\n",
      "[CV 2/5; 22/32] END criterion=entropy, max_features=2, n_estimators=100;, score=0.807 total time=   0.6s\n",
      "[CV 3/5; 22/32] START criterion=entropy, max_features=2, n_estimators=100.......\n",
      "[CV 3/5; 22/32] END criterion=entropy, max_features=2, n_estimators=100;, score=0.818 total time=   0.6s\n",
      "[CV 4/5; 22/32] START criterion=entropy, max_features=2, n_estimators=100.......\n",
      "[CV 4/5; 22/32] END criterion=entropy, max_features=2, n_estimators=100;, score=0.811 total time=   0.6s\n",
      "[CV 5/5; 22/32] START criterion=entropy, max_features=2, n_estimators=100.......\n",
      "[CV 5/5; 22/32] END criterion=entropy, max_features=2, n_estimators=100;, score=0.804 total time=   0.6s\n",
      "[CV 1/5; 23/32] START criterion=entropy, max_features=2, n_estimators=150.......\n",
      "[CV 1/5; 23/32] END criterion=entropy, max_features=2, n_estimators=150;, score=0.816 total time=   0.9s\n",
      "[CV 2/5; 23/32] START criterion=entropy, max_features=2, n_estimators=150.......\n",
      "[CV 2/5; 23/32] END criterion=entropy, max_features=2, n_estimators=150;, score=0.808 total time=   0.9s\n",
      "[CV 3/5; 23/32] START criterion=entropy, max_features=2, n_estimators=150.......\n",
      "[CV 3/5; 23/32] END criterion=entropy, max_features=2, n_estimators=150;, score=0.820 total time=   0.9s\n",
      "[CV 4/5; 23/32] START criterion=entropy, max_features=2, n_estimators=150.......\n",
      "[CV 4/5; 23/32] END criterion=entropy, max_features=2, n_estimators=150;, score=0.811 total time=   0.9s\n",
      "[CV 5/5; 23/32] START criterion=entropy, max_features=2, n_estimators=150.......\n",
      "[CV 5/5; 23/32] END criterion=entropy, max_features=2, n_estimators=150;, score=0.804 total time=   0.9s\n",
      "[CV 1/5; 24/32] START criterion=entropy, max_features=2, n_estimators=200.......\n",
      "[CV 1/5; 24/32] END criterion=entropy, max_features=2, n_estimators=200;, score=0.816 total time=   1.2s\n",
      "[CV 2/5; 24/32] START criterion=entropy, max_features=2, n_estimators=200.......\n",
      "[CV 2/5; 24/32] END criterion=entropy, max_features=2, n_estimators=200;, score=0.808 total time=   1.2s\n",
      "[CV 3/5; 24/32] START criterion=entropy, max_features=2, n_estimators=200.......\n",
      "[CV 3/5; 24/32] END criterion=entropy, max_features=2, n_estimators=200;, score=0.820 total time=   1.2s\n",
      "[CV 4/5; 24/32] START criterion=entropy, max_features=2, n_estimators=200.......\n",
      "[CV 4/5; 24/32] END criterion=entropy, max_features=2, n_estimators=200;, score=0.810 total time=   1.2s\n",
      "[CV 5/5; 24/32] START criterion=entropy, max_features=2, n_estimators=200.......\n",
      "[CV 5/5; 24/32] END criterion=entropy, max_features=2, n_estimators=200;, score=0.805 total time=   1.2s\n",
      "[CV 1/5; 25/32] START criterion=entropy, max_features=3, n_estimators=50........\n",
      "[CV 1/5; 25/32] END criterion=entropy, max_features=3, n_estimators=50;, score=0.816 total time=   0.3s\n",
      "[CV 2/5; 25/32] START criterion=entropy, max_features=3, n_estimators=50........\n",
      "[CV 2/5; 25/32] END criterion=entropy, max_features=3, n_estimators=50;, score=0.808 total time=   0.3s\n",
      "[CV 3/5; 25/32] START criterion=entropy, max_features=3, n_estimators=50........\n",
      "[CV 3/5; 25/32] END criterion=entropy, max_features=3, n_estimators=50;, score=0.819 total time=   0.3s\n",
      "[CV 4/5; 25/32] START criterion=entropy, max_features=3, n_estimators=50........\n",
      "[CV 4/5; 25/32] END criterion=entropy, max_features=3, n_estimators=50;, score=0.811 total time=   0.3s\n",
      "[CV 5/5; 25/32] START criterion=entropy, max_features=3, n_estimators=50........\n",
      "[CV 5/5; 25/32] END criterion=entropy, max_features=3, n_estimators=50;, score=0.804 total time=   0.3s\n",
      "[CV 1/5; 26/32] START criterion=entropy, max_features=3, n_estimators=100.......\n",
      "[CV 1/5; 26/32] END criterion=entropy, max_features=3, n_estimators=100;, score=0.816 total time=   0.6s\n",
      "[CV 2/5; 26/32] START criterion=entropy, max_features=3, n_estimators=100.......\n",
      "[CV 2/5; 26/32] END criterion=entropy, max_features=3, n_estimators=100;, score=0.807 total time=   0.6s\n",
      "[CV 3/5; 26/32] START criterion=entropy, max_features=3, n_estimators=100.......\n",
      "[CV 3/5; 26/32] END criterion=entropy, max_features=3, n_estimators=100;, score=0.818 total time=   0.6s\n",
      "[CV 4/5; 26/32] START criterion=entropy, max_features=3, n_estimators=100.......\n",
      "[CV 4/5; 26/32] END criterion=entropy, max_features=3, n_estimators=100;, score=0.811 total time=   0.6s\n",
      "[CV 5/5; 26/32] START criterion=entropy, max_features=3, n_estimators=100.......\n",
      "[CV 5/5; 26/32] END criterion=entropy, max_features=3, n_estimators=100;, score=0.804 total time=   0.6s\n",
      "[CV 1/5; 27/32] START criterion=entropy, max_features=3, n_estimators=150.......\n",
      "[CV 1/5; 27/32] END criterion=entropy, max_features=3, n_estimators=150;, score=0.816 total time=   1.0s\n",
      "[CV 2/5; 27/32] START criterion=entropy, max_features=3, n_estimators=150.......\n",
      "[CV 2/5; 27/32] END criterion=entropy, max_features=3, n_estimators=150;, score=0.808 total time=   1.0s\n",
      "[CV 3/5; 27/32] START criterion=entropy, max_features=3, n_estimators=150.......\n",
      "[CV 3/5; 27/32] END criterion=entropy, max_features=3, n_estimators=150;, score=0.819 total time=   1.0s\n",
      "[CV 4/5; 27/32] START criterion=entropy, max_features=3, n_estimators=150.......\n",
      "[CV 4/5; 27/32] END criterion=entropy, max_features=3, n_estimators=150;, score=0.811 total time=   1.0s\n",
      "[CV 5/5; 27/32] START criterion=entropy, max_features=3, n_estimators=150.......\n",
      "[CV 5/5; 27/32] END criterion=entropy, max_features=3, n_estimators=150;, score=0.804 total time=   1.0s\n",
      "[CV 1/5; 28/32] START criterion=entropy, max_features=3, n_estimators=200.......\n",
      "[CV 1/5; 28/32] END criterion=entropy, max_features=3, n_estimators=200;, score=0.816 total time=   1.4s\n",
      "[CV 2/5; 28/32] START criterion=entropy, max_features=3, n_estimators=200.......\n",
      "[CV 2/5; 28/32] END criterion=entropy, max_features=3, n_estimators=200;, score=0.807 total time=   1.3s\n",
      "[CV 3/5; 28/32] START criterion=entropy, max_features=3, n_estimators=200.......\n",
      "[CV 3/5; 28/32] END criterion=entropy, max_features=3, n_estimators=200;, score=0.819 total time=   1.3s\n",
      "[CV 4/5; 28/32] START criterion=entropy, max_features=3, n_estimators=200.......\n",
      "[CV 4/5; 28/32] END criterion=entropy, max_features=3, n_estimators=200;, score=0.811 total time=   1.3s\n",
      "[CV 5/5; 28/32] START criterion=entropy, max_features=3, n_estimators=200.......\n",
      "[CV 5/5; 28/32] END criterion=entropy, max_features=3, n_estimators=200;, score=0.805 total time=   1.3s\n",
      "[CV 1/5; 29/32] START criterion=entropy, max_features=4, n_estimators=50........\n",
      "[CV 1/5; 29/32] END criterion=entropy, max_features=4, n_estimators=50;, score=0.815 total time=   0.3s\n",
      "[CV 2/5; 29/32] START criterion=entropy, max_features=4, n_estimators=50........\n",
      "[CV 2/5; 29/32] END criterion=entropy, max_features=4, n_estimators=50;, score=0.807 total time=   0.3s\n",
      "[CV 3/5; 29/32] START criterion=entropy, max_features=4, n_estimators=50........\n",
      "[CV 3/5; 29/32] END criterion=entropy, max_features=4, n_estimators=50;, score=0.818 total time=   0.3s\n",
      "[CV 4/5; 29/32] START criterion=entropy, max_features=4, n_estimators=50........\n",
      "[CV 4/5; 29/32] END criterion=entropy, max_features=4, n_estimators=50;, score=0.811 total time=   0.3s\n",
      "[CV 5/5; 29/32] START criterion=entropy, max_features=4, n_estimators=50........\n",
      "[CV 5/5; 29/32] END criterion=entropy, max_features=4, n_estimators=50;, score=0.804 total time=   0.3s\n",
      "[CV 1/5; 30/32] START criterion=entropy, max_features=4, n_estimators=100.......\n",
      "[CV 1/5; 30/32] END criterion=entropy, max_features=4, n_estimators=100;, score=0.815 total time=   0.7s\n",
      "[CV 2/5; 30/32] START criterion=entropy, max_features=4, n_estimators=100.......\n",
      "[CV 2/5; 30/32] END criterion=entropy, max_features=4, n_estimators=100;, score=0.806 total time=   0.7s\n",
      "[CV 3/5; 30/32] START criterion=entropy, max_features=4, n_estimators=100.......\n",
      "[CV 3/5; 30/32] END criterion=entropy, max_features=4, n_estimators=100;, score=0.817 total time=   0.7s\n",
      "[CV 4/5; 30/32] START criterion=entropy, max_features=4, n_estimators=100.......\n",
      "[CV 4/5; 30/32] END criterion=entropy, max_features=4, n_estimators=100;, score=0.811 total time=   0.7s\n",
      "[CV 5/5; 30/32] START criterion=entropy, max_features=4, n_estimators=100.......\n",
      "[CV 5/5; 30/32] END criterion=entropy, max_features=4, n_estimators=100;, score=0.804 total time=   0.7s\n",
      "[CV 1/5; 31/32] START criterion=entropy, max_features=4, n_estimators=150.......\n",
      "[CV 1/5; 31/32] END criterion=entropy, max_features=4, n_estimators=150;, score=0.815 total time=   1.1s\n",
      "[CV 2/5; 31/32] START criterion=entropy, max_features=4, n_estimators=150.......\n",
      "[CV 2/5; 31/32] END criterion=entropy, max_features=4, n_estimators=150;, score=0.807 total time=   1.1s\n",
      "[CV 3/5; 31/32] START criterion=entropy, max_features=4, n_estimators=150.......\n",
      "[CV 3/5; 31/32] END criterion=entropy, max_features=4, n_estimators=150;, score=0.819 total time=   1.1s\n",
      "[CV 4/5; 31/32] START criterion=entropy, max_features=4, n_estimators=150.......\n",
      "[CV 4/5; 31/32] END criterion=entropy, max_features=4, n_estimators=150;, score=0.811 total time=   1.1s\n",
      "[CV 5/5; 31/32] START criterion=entropy, max_features=4, n_estimators=150.......\n",
      "[CV 5/5; 31/32] END criterion=entropy, max_features=4, n_estimators=150;, score=0.804 total time=   1.1s\n",
      "[CV 1/5; 32/32] START criterion=entropy, max_features=4, n_estimators=200.......\n",
      "[CV 1/5; 32/32] END criterion=entropy, max_features=4, n_estimators=200;, score=0.816 total time=   1.5s\n",
      "[CV 2/5; 32/32] START criterion=entropy, max_features=4, n_estimators=200.......\n",
      "[CV 2/5; 32/32] END criterion=entropy, max_features=4, n_estimators=200;, score=0.806 total time=   1.5s\n",
      "[CV 3/5; 32/32] START criterion=entropy, max_features=4, n_estimators=200.......\n",
      "[CV 3/5; 32/32] END criterion=entropy, max_features=4, n_estimators=200;, score=0.819 total time=   1.5s\n",
      "[CV 4/5; 32/32] START criterion=entropy, max_features=4, n_estimators=200.......\n",
      "[CV 4/5; 32/32] END criterion=entropy, max_features=4, n_estimators=200;, score=0.811 total time=   1.5s\n",
      "[CV 5/5; 32/32] START criterion=entropy, max_features=4, n_estimators=200.......\n",
      "[CV 5/5; 32/32] END criterion=entropy, max_features=4, n_estimators=200;, score=0.804 total time=   1.5s\n",
      "Random Forest GridSearchCV best score = 0.8118535604001972\n",
      "Random Forest GridSearchCV best parameters = {'criterion': 'entropy', 'max_features': 1, 'n_estimators': 200}\n",
      "Random Forest GridSearchCV deceased class f1-score = 0.7387968276484622\n",
      "Random Forest GridSearchCV accuracy score = 0.8264186737050478\n"
     ]
    }
   ],
   "source": [
    "# Takes about 3-4 minutes to run.\n",
    "\n",
    "# Decide number of k-fold splits\n",
    "k = 5\n",
    "# Create model with blank parameters\n",
    "rf_model = RandomForestClassifier(random_state = 44)\n",
    "# Create space of possible parameters\n",
    "parameter_search_space = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'criterion': [\"gini\", \"entropy\"],\n",
    "    'max_features': [1, 2, 3, 4]\n",
    "  }\n",
    "# Create grid search cross validation object\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=parameter_search_space,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=k,\n",
    "    verbose=10\n",
    ")\n",
    "# Put data and labels in proper format\n",
    "data = train_data.iloc[:, :4].values\n",
    "labels = train_data.iloc[:, 4].values.ravel()\n",
    "# Fit grid search object\n",
    "grid_search_cv.fit(data, labels)\n",
    "# Print and save results.\n",
    "print(\"Random Forest GridSearchCV best score = \" + str(grid_search_cv.best_score_))\n",
    "print(\"Random Forest GridSearchCV best parameters = \" + str(grid_search_cv.best_params_))\n",
    "predictions = grid_search_cv.predict(data)\n",
    "_, _, fscore, _ = precision_recall_fscore_support(predictions, labels)\n",
    "print(\"Random Forest GridSearchCV deceased class f1-score = \" + str(fscore[0]))\n",
    "accuracy = accuracy_score(predictions, labels)\n",
    "print(\"Random Forest GridSearchCV accuracy score = \" + str(accuracy))\n",
    "pd.DataFrame(grid_search_cv.cv_results_).to_csv(\"rf_results.csv\")\n",
    "rf_model = grid_search_cv.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.409 total time=   1.1s\n",
      "[CV 2/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.740 total time=   4.7s\n",
      "[CV 3/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.741 total time=   7.7s\n",
      "[CV 4/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.753 total time=   5.7s\n",
      "[CV 5/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.759 total time=   4.5s\n",
      "[CV 1/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.775 total time=   6.5s\n",
      "[CV 2/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.765 total time=  10.3s\n",
      "[CV 3/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.754 total time=   5.4s\n",
      "[CV 4/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.765 total time=   9.7s\n",
      "[CV 5/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.756 total time=   3.6s\n",
      "[CV 1/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.772 total time=   9.1s\n",
      "[CV 2/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.760 total time=   8.9s\n",
      "[CV 3/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 3/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.768 total time=   8.6s\n",
      "[CV 4/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.757 total time=   9.0s\n",
      "[CV 5/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.563 total time=   9.0s\n",
      "[CV 1/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.775 total time=   4.9s\n",
      "[CV 2/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.762 total time=   3.7s\n",
      "[CV 3/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.759 total time=   2.2s\n",
      "[CV 4/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.777 total time=   8.0s\n",
      "[CV 5/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.771 total time=   6.7s\n",
      "[CV 1/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.761 total time=   4.2s\n",
      "[CV 2/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.761 total time=   2.4s\n",
      "[CV 3/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.757 total time=   4.3s\n",
      "[CV 4/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.758 total time=   4.5s\n",
      "[CV 5/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.715 total time=   2.8s\n",
      "[CV 1/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.776 total time=   5.6s\n",
      "[CV 2/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.763 total time=   2.6s\n",
      "[CV 3/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.766 total time=   4.8s\n",
      "[CV 4/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.782 total time=   4.3s\n",
      "[CV 5/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.770 total time=   4.6s\n",
      "[CV 1/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.773 total time=   5.4s\n",
      "[CV 2/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.762 total time=   5.3s\n",
      "[CV 3/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 3/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.764 total time=   4.5s\n",
      "[CV 4/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.765 total time=   5.3s\n",
      "[CV 5/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.768 total time=   5.2s\n",
      "[CV 1/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.775 total time=   4.0s\n",
      "[CV 2/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.763 total time=   5.0s\n",
      "[CV 3/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.770 total time=   3.8s\n",
      "[CV 4/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.769 total time=   5.5s\n",
      "[CV 5/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.764 total time=   4.8s\n",
      "[CV 1/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.752 total time=   6.3s\n",
      "[CV 2/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.416 total time=   1.1s\n",
      "[CV 3/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.757 total time=   7.0s\n",
      "[CV 4/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.769 total time=   6.3s\n",
      "[CV 5/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.197 total time=   1.2s\n",
      "[CV 1/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.772 total time=   5.1s\n",
      "[CV 2/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.761 total time=   2.8s\n",
      "[CV 3/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.770 total time=   8.0s\n",
      "[CV 4/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.763 total time=   7.1s\n",
      "[CV 5/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.762 total time=   4.9s\n",
      "[CV 1/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.582 total time=   9.6s\n",
      "[CV 2/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.766 total time=   9.4s\n",
      "[CV 3/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 3/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.766 total time=   7.4s\n",
      "[CV 4/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 4/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.588 total time=   6.6s\n",
      "[CV 5/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.745 total time=   9.2s\n",
      "[CV 1/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.768 total time=   4.7s\n",
      "[CV 2/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.760 total time=   4.8s\n",
      "[CV 3/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.761 total time=   4.6s\n",
      "[CV 4/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.771 total time=   5.3s\n",
      "[CV 5/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.754 total time=   7.4s\n",
      "[CV 1/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.739 total time=   2.6s\n",
      "[CV 2/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.754 total time=   2.9s\n",
      "[CV 3/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.734 total time=   3.9s\n",
      "[CV 4/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.771 total time=   3.3s\n",
      "[CV 5/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.748 total time=   3.7s\n",
      "[CV 1/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.772 total time=   2.7s\n",
      "[CV 2/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.765 total time=   2.9s\n",
      "[CV 3/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.766 total time=   3.1s\n",
      "[CV 4/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.771 total time=   3.0s\n",
      "[CV 5/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.773 total time=   4.4s\n",
      "[CV 1/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.770 total time=   5.2s\n",
      "[CV 2/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.759 total time=   5.0s\n",
      "[CV 3/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.767 total time=   5.1s\n",
      "[CV 4/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.772 total time=   5.1s\n",
      "[CV 5/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 5/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.752 total time=   4.1s\n",
      "[CV 1/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.773 total time=   4.3s\n",
      "[CV 2/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.760 total time=   2.3s\n",
      "[CV 3/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.763 total time=   3.4s\n",
      "[CV 4/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.776 total time=   3.9s\n",
      "[CV 5/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.773 total time=   2.2s\n",
      "[CV 1/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.737 total time=   4.6s\n",
      "[CV 2/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.762 total time=   8.2s\n",
      "[CV 3/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.763 total time=   6.5s\n",
      "[CV 4/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.736 total time=   3.2s\n",
      "[CV 5/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.172 total time=   0.6s\n",
      "[CV 1/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.755 total time=   3.2s\n",
      "[CV 2/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.760 total time=   3.3s\n",
      "[CV 3/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.760 total time=   3.4s\n",
      "[CV 4/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.756 total time=   3.1s\n",
      "[CV 5/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.771 total time=   6.5s\n",
      "[CV 1/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.773 total time=   8.0s\n",
      "[CV 2/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.761 total time=   8.0s\n",
      "[CV 3/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.761 total time=   8.0s\n",
      "[CV 4/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 4/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.763 total time=   7.0s\n",
      "[CV 5/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 5/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.762 total time=   7.1s\n",
      "[CV 1/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.773 total time=   3.0s\n",
      "[CV 2/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.759 total time=   2.2s\n",
      "[CV 3/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.755 total time=   4.2s\n",
      "[CV 4/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.775 total time=   7.4s\n",
      "[CV 5/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.771 total time=   3.4s\n",
      "[CV 1/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.773 total time=   2.6s\n",
      "[CV 2/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.759 total time=   3.1s\n",
      "[CV 3/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.751 total time=   3.8s\n",
      "[CV 4/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.771 total time=   3.7s\n",
      "[CV 5/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.746 total time=   2.5s\n",
      "[CV 1/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.738 total time=   1.7s\n",
      "[CV 2/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.765 total time=   4.0s\n",
      "[CV 3/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.762 total time=   1.6s\n",
      "[CV 4/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.772 total time=   2.7s\n",
      "[CV 5/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.757 total time=   3.0s\n",
      "[CV 1/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.773 total time=   4.6s\n",
      "[CV 2/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 2/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.760 total time=   4.1s\n",
      "[CV 3/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.760 total time=   4.7s\n",
      "[CV 4/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 4/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.768 total time=   4.0s\n",
      "[CV 5/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.757 total time=   4.6s\n",
      "[CV 1/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.772 total time=   2.7s\n",
      "[CV 2/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.763 total time=   2.1s\n",
      "[CV 3/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.760 total time=   3.0s\n",
      "[CV 4/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.763 total time=   2.6s\n",
      "[CV 5/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.759 total time=   2.2s\n",
      "[CV 1/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.763 total time=   6.5s\n",
      "[CV 2/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.754 total time=   4.4s\n",
      "[CV 3/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.759 total time=   4.0s\n",
      "[CV 4/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.764 total time=   5.4s\n",
      "[CV 5/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.750 total time=   5.1s\n",
      "[CV 1/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.775 total time=   3.5s\n",
      "[CV 2/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.752 total time=   2.5s\n",
      "[CV 3/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.739 total time=   2.1s\n",
      "[CV 4/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.767 total time=   2.6s\n",
      "[CV 5/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.760 total time=   5.4s\n",
      "[CV 1/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.775 total time=   7.8s\n",
      "[CV 2/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.763 total time=   7.8s\n",
      "[CV 3/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 3/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.762 total time=   6.4s\n",
      "[CV 4/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 4/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.764 total time=   7.4s\n",
      "[CV 5/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.763 total time=   8.1s\n",
      "[CV 1/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.773 total time=   2.3s\n",
      "[CV 2/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.760 total time=   4.1s\n",
      "[CV 3/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.767 total time=   4.4s\n",
      "[CV 4/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.775 total time=   5.3s\n",
      "[CV 5/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.754 total time=   5.0s\n",
      "[CV 1/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.771 total time=   1.7s\n",
      "[CV 2/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.750 total time=   3.4s\n",
      "[CV 3/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.766 total time=   4.5s\n",
      "[CV 4/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.756 total time=   3.4s\n",
      "[CV 5/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.769 total time=   4.5s\n",
      "[CV 1/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.774 total time=   2.1s\n",
      "[CV 2/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.758 total time=   2.4s\n",
      "[CV 3/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.750 total time=   2.1s\n",
      "[CV 4/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.769 total time=   2.6s\n",
      "[CV 5/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.761 total time=   2.3s\n",
      "[CV 1/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.774 total time=   4.7s\n",
      "[CV 2/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 2/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.759 total time=   4.6s\n",
      "[CV 3/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.761 total time=   4.8s\n",
      "[CV 4/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.773 total time=   4.7s\n",
      "[CV 5/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.758 total time=   4.5s\n",
      "[CV 1/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.758 total time=   2.7s\n",
      "[CV 2/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.763 total time=   2.6s\n",
      "[CV 3/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.762 total time=   1.7s\n",
      "[CV 4/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.756 total time=   1.9s\n",
      "[CV 5/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.769 total time=   2.2s\n",
      "MLP Classifier GridSearchCV best score = 0.7715270977807592\n",
      "MLP Classifier GridSearchCV best parameters = {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "MLP Classifier GridSearchCV deceased class f1-score = 0.6632205718772493\n",
      "MLP Classifier GridSearchCV accuracy score = 0.7753216760145166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Takes about 12 minutes to run.\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# x_train = train_data[['age', 'country', 'chronic_disease_binary', 'Case_Fatality_Ratio']]\n",
    "# y_train = train_data[['outcome_group']]\n",
    "mlp_gs = MLPClassifier()\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "data = train_data.iloc[:, :4].values\n",
    "labels = train_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=mlp_gs,\n",
    "    param_grid=parameter_space,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "grid_search_cv.fit(data,labels.ravel())\n",
    "\n",
    "print(\"MLP Classifier GridSearchCV best score = \" + str(grid_search_cv.best_score_))\n",
    "print(\"MLP Classifier GridSearchCV best parameters = \" + str(grid_search_cv.best_params_))\n",
    "predictions = grid_search_cv.predict(data)\n",
    "_, _, fscore, _ = precision_recall_fscore_support(predictions, labels)\n",
    "print(\"MLP Classifier GridSearchCV deceased class f1-score = \" + str(fscore[0]))\n",
    "accuracy = accuracy_score(predictions, labels)\n",
    "print(\"MLP Classifier GridSearchCV accuracy score = \" + str(accuracy))\n",
    "pd.DataFrame(grid_search_cv.cv_results_).to_csv(\"MLP Classifier_results.csv\")\n",
    "mlp_gs = grid_search_cv.best_estimator_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Check for overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset F1-Score = 0.8212300928365347\n",
      "Validation Dataset F1-Score = 0.8173276137798035\n"
     ]
    }
   ],
   "source": [
    "# Checking for overfitting on XG Boost model by comparing results on train versus validation datasets.\n",
    "train_data_formatted = train_data.iloc[:, :4].values\n",
    "train_labels_truth = train_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "train_labels_predicted = xgb_model.predict(train_data_formatted)\n",
    "train_data_score = f1_score(train_labels_predicted, train_labels_truth, average = \"macro\")\n",
    "\n",
    "validation_data_formatted = validation_data.iloc[:, :4].values\n",
    "validation_labels_truth = validation_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "validation_labels_predicted = xgb_model.predict(validation_data_formatted)\n",
    "validation_data_score = f1_score(validation_labels_predicted, validation_labels_truth, average = \"macro\")\n",
    "\n",
    "print(\"Training Dataset F1-Score = \" + str(train_data_score))\n",
    "print(\"Validation Dataset F1-Score = \" + str(validation_data_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset F1-Score = 0.8218275664308504\n",
      "Validation Dataset F1-Score = 0.8189428961273375\n",
      "Validation dataset accuracy score = 0.8231606730451996\n"
     ]
    }
   ],
   "source": [
    "# Checking for overfitting on Random Forest model by comparing results on train versus validation datasets.\n",
    "train_data_formatted = train_data.iloc[:, :4].values\n",
    "train_labels_truth = train_data.iloc[:, 4].values.ravel()\n",
    "train_labels_predicted = rf_model.predict(train_data_formatted)\n",
    "train_data_score = f1_score(train_labels_predicted, train_labels_truth, average = \"macro\")\n",
    "\n",
    "validation_data_formatted = validation_data.iloc[:, :4].values\n",
    "validation_labels_truth = validation_data.iloc[:, 4].values.ravel()\n",
    "validation_labels_predicted = rf_model.predict(validation_data_formatted)\n",
    "validation_data_score = f1_score(validation_labels_predicted, validation_labels_truth, average = \"macro\")\n",
    "\n",
    "print(\"Training Dataset F1-Score = \" + str(train_data_score))\n",
    "print(\"Validation Dataset F1-Score = \" + str(validation_data_score))\n",
    "\n",
    "accuracy = accuracy_score(validation_labels_predicted, validation_labels_truth)\n",
    "print(\"Validation dataset accuracy score = \" + str(accuracy)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset F1-Score = 0.7699401558993139\n",
      "Validation Dataset F1-Score = 0.7707827995218226\n"
     ]
    }
   ],
   "source": [
    "train_data_formatted = train_data.iloc[:, :4].values\n",
    "train_labels_truth = train_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "train_labels_predicted = mlp_gs.predict(train_data_formatted)\n",
    "train_data_score = f1_score(train_labels_predicted, train_labels_truth, average = \"macro\")\n",
    "\n",
    "validation_data_formatted = validation_data.iloc[:, :4].values\n",
    "validation_labels_truth = validation_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "validation_labels_predicted = mlp_gs.predict(validation_data_formatted)\n",
    "validation_data_score = f1_score(validation_labels_predicted, validation_labels_truth, average = \"macro\")\n",
    "\n",
    "print(\"Training Dataset F1-Score = \" + str(train_data_score))\n",
    "print(\"Validation Dataset F1-Score = \" + str(validation_data_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.7 Prediction on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# USING XG BOOST FOR NOW BUT WE CAN SUB THIS OUT FOR BEST PERFORMING MODEL LATER\n",
    "testing_data = test_data.iloc[:, :4].values\n",
    "predicted_labels = xgb_model.predict(testing_data)\n",
    "# CHANGE MODEL NAME TO BEST PERFORMING MODEL LATER\n",
    "model_name = \"xgboost\"\n",
    "result_data_frame = pd.DataFrame(testing_data, columns=[\"age\", \"country\", \"chronic_disease_binary\", \"Case_Fatality_Ratio\"])\n",
    "\n",
    "# This function is from the TA\n",
    "def create_submission_file(y_preds, file_name):\n",
    "    with open(file_name, 'w') as csvfile:\n",
    "        wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow([\"Id\", \"Prediction\"])\n",
    "        for i, pred in enumerate(y_preds):\n",
    "            wr.writerow([str(i), str(pred)])\n",
    "create_submission_file(predicted_labels, \"submission_\"+model_name+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the final model selection, we can delete one of these\n",
    "\n",
    "import csv\n",
    "testing_data = test_data.iloc[:, :4].values\n",
    "predicted_labels = rf_model.predict(testing_data)\n",
    "\n",
    "model_name = \"random_forest\"\n",
    "result_data_frame = pd.DataFrame(testing_data, columns=[\"age\", \"country\", \"chronic_disease_binary\", \"Case_Fatality_Ratio\"])\n",
    "\n",
    "# This function is from the TA\n",
    "def create_submission_file(y_preds, file_name):\n",
    "    with open(file_name, 'w') as csvfile:\n",
    "        wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow([\"Id\", \"Prediction\"])\n",
    "        for i, pred in enumerate(y_preds):\n",
    "            wr.writerow([str(i), str(pred)])\n",
    "create_submission_file(predicted_labels, \"submission_\"+model_name+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ebeb2db109b4e4030ca6b0eb886199afc2cd913864cd051a344632d0064a896"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
