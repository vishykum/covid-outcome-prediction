{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_data = pd.read_excel(\"data/cases_2021_train_processed_2.xlsx\")\n",
    "test_data = pd.read_excel(\"data/cases_2021_test_processed_unlabelled_2.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.copy()\n",
    "train = train[['age', 'country', 'chronic_disease_binary', 'Case_Fatality_Ratio','outcome_group']]\n",
    "test = test_data.copy()\n",
    "test = test[['age', 'country', 'chronic_disease_binary', 'Case_Fatality_Ratio']]\n",
    "train_data, test_data = train,test "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Feature Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.copy()\n",
    "train['country'] = pd.factorize(train['country'])[0]\n",
    "train['chronic_disease_binary'] = pd.factorize(train['chronic_disease_binary'])[0]\n",
    "new_label = {\"outcome_group\": {\"deceased\": 0, \"hospitalized\": 1, \"nonhospitalized\": 2}}\n",
    "train.replace(new_label, inplace = True)\n",
    "test = test_data.copy()\n",
    "test['country'] = pd.factorize(test['country'])[0]\n",
    "test['chronic_disease_binary'] = pd.factorize(test['chronic_disease_binary'])[0]\n",
    "train_data, test_data = train,test "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Balancing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before Balancing,\n",
      "outcome_group\n",
      "0      997\n",
      "1    13241\n",
      "2     2974\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Balancing,\n",
      "outcome_group\n",
      "0     9970\n",
      "1    10564\n",
      "2     9814\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_train_dataset_pie_chart(train_dataset: pd.DataFrame, title: str):\n",
    "    plt.figure()\n",
    "    data = train_dataset.groupby(\"outcome_group\").size()\n",
    "    print(\"\\n\" + title + \",\")\n",
    "    print(data)\n",
    "    data = [int(data[0]), int(data[1]), int(data[2])]\n",
    "    labels = [\"deceased\", \"hospitalized\", \"nonhospitalized\"]\n",
    "    colours = sns.color_palette('pastel')[0:4]\n",
    "    plt.pie(x=data, labels=labels, colors=colours, autopct='%.0f%%')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "show_train_dataset_pie_chart(train_data, \"Before Balancing\")\n",
    "\n",
    "deceased = train_data[train_data[\"outcome_group\"] == 0]\n",
    "new_deceased = deceased.sample(frac=10, replace=True, random_state=1)\n",
    "new_deceased.reset_index(inplace=True, drop=True)\n",
    "\n",
    "hospitalized = train_data[train_data[\"outcome_group\"] == 1]\n",
    "hospitalized_sample = np.random.choice(hospitalized.index, 3000, replace=True)\n",
    "new_hospitalized = hospitalized.drop(hospitalized_sample)\n",
    "new_hospitalized.reset_index(inplace=True, drop=True)\n",
    "\n",
    "nonhospitalized = train_data[train_data[\"outcome_group\"] == 2]\n",
    "new_nonhospitalized = nonhospitalized.sample(frac=3.3, replace=True, random_state=1)\n",
    "new_nonhospitalized.reset_index(inplace=True, drop=True)\n",
    "\n",
    "new_train = pd.concat([new_deceased, new_hospitalized, new_nonhospitalized])\n",
    "new_train.sort_index(axis = 0, inplace=True)\n",
    "new_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "show_train_dataset_pie_chart(new_train, \"After Balancing\")\n",
    "\n",
    "train_data = new_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Building Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation Split,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(train_data, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.811 total time=   0.6s\n",
      "[CV 2/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.814 total time=   0.6s\n",
      "[CV 3/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.801 total time=   0.6s\n",
      "[CV 4/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.822 total time=   0.6s\n",
      "[CV 5/5; 1/12] START learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 1/12] END learning_rate=0.2, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.807 total time=   0.6s\n",
      "[CV 1/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.814 total time=   1.0s\n",
      "[CV 2/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.814 total time=   1.0s\n",
      "[CV 3/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.801 total time=   1.0s\n",
      "[CV 4/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.823 total time=   1.0s\n",
      "[CV 5/5; 2/12] START learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 2/12] END learning_rate=0.2, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.809 total time=   1.0s\n",
      "[CV 1/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.812 total time=   0.8s\n",
      "[CV 2/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.816 total time=   0.8s\n",
      "[CV 3/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.801 total time=   0.8s\n",
      "[CV 4/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.825 total time=   0.8s\n",
      "[CV 5/5; 3/12] START learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 3/12] END learning_rate=0.2, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.809 total time=   0.8s\n",
      "[CV 1/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.814 total time=   1.3s\n",
      "[CV 2/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.816 total time=   1.3s\n",
      "[CV 3/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.800 total time=   1.3s\n",
      "[CV 4/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.825 total time=   1.4s\n",
      "[CV 5/5; 4/12] START learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 4/12] END learning_rate=0.2, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.3s\n",
      "[CV 1/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.814 total time=   1.0s\n",
      "[CV 2/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.817 total time=   1.0s\n",
      "[CV 3/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.801 total time=   1.0s\n",
      "[CV 4/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.825 total time=   1.0s\n",
      "[CV 5/5; 5/12] START learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 5/12] END learning_rate=0.2, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.0s\n",
      "[CV 1/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.814 total time=   1.6s\n",
      "[CV 2/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.816 total time=   1.6s\n",
      "[CV 3/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.801 total time=   1.6s\n",
      "[CV 4/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.824 total time=   1.6s\n",
      "[CV 5/5; 6/12] START learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 6/12] END learning_rate=0.2, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.7s\n",
      "[CV 1/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.812 total time=   0.6s\n",
      "[CV 2/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.815 total time=   0.6s\n",
      "[CV 3/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.801 total time=   0.6s\n",
      "[CV 4/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.824 total time=   0.6s\n",
      "[CV 5/5; 7/12] START learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 7/12] END learning_rate=0.3, max_depth=6, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.810 total time=   0.6s\n",
      "[CV 1/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.815 total time=   1.0s\n",
      "[CV 2/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.816 total time=   1.0s\n",
      "[CV 3/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.801 total time=   1.0s\n",
      "[CV 4/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.825 total time=   1.0s\n",
      "[CV 5/5; 8/12] START learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 8/12] END learning_rate=0.3, max_depth=6, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.0s\n",
      "[CV 1/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.814 total time=   0.7s\n",
      "[CV 2/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.816 total time=   0.8s\n",
      "[CV 3/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.801 total time=   0.8s\n",
      "[CV 4/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.825 total time=   0.8s\n",
      "[CV 5/5; 9/12] START learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 9/12] END learning_rate=0.3, max_depth=8, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.811 total time=   0.8s\n",
      "[CV 1/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.814 total time=   1.3s\n",
      "[CV 2/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.816 total time=   1.3s\n",
      "[CV 3/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.800 total time=   1.3s\n",
      "[CV 4/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.825 total time=   1.3s\n",
      "[CV 5/5; 10/12] START learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 10/12] END learning_rate=0.3, max_depth=8, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.810 total time=   1.3s\n",
      "[CV 1/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.813 total time=   0.9s\n",
      "[CV 2/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.816 total time=   0.9s\n",
      "[CV 3/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.801 total time=   1.0s\n",
      "[CV 4/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.824 total time=   1.0s\n",
      "[CV 5/5; 11/12] START learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 11/12] END learning_rate=0.3, max_depth=10, n_estimators=150, num_class=3, objective=multi:softmax;, score=0.810 total time=   0.9s\n",
      "[CV 1/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 1/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.813 total time=   1.6s\n",
      "[CV 2/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 2/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.815 total time=   1.6s\n",
      "[CV 3/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 3/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.800 total time=   1.6s\n",
      "[CV 4/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 4/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.824 total time=   1.6s\n",
      "[CV 5/5; 12/12] START learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax\n",
      "[CV 5/5; 12/12] END learning_rate=0.3, max_depth=10, n_estimators=250, num_class=3, objective=multi:softmax;, score=0.811 total time=   1.6s\n",
      "XG Boost GridSearchCV best score = 0.8132172466106876\n",
      "XG Boost GridSearchCV best parameters = {'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 250, 'num_class': 3, 'objective': 'multi:softmax'}\n",
      "XG Boost GridSearchCV deceased class f1-score = 0.7352326189231573\n",
      "XG Boost GridSearchCV accuracy score = 0.8261800807315265\n"
     ]
    }
   ],
   "source": [
    "# Takes about 4 minutes to run.\n",
    "\n",
    "# Decide number of k-fold splits\n",
    "k = 5\n",
    "# Create model with blank parameters\n",
    "xgb_model = xgb.XGBClassifier(random_state = 1)\n",
    "# Create space of possible parameters\n",
    "parameter_search_space = {\n",
    "    \"learning_rate\": [0.2, 0.3],\n",
    "    \"max_depth\": [6, 8, 10],\n",
    "    \"n_estimators\": [150, 250],\n",
    "    \"objective\": [\"multi:softmax\"],\n",
    "    \"num_class\": [3]\n",
    "}\n",
    "# Create grid search cross validation object\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=parameter_search_space,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=k,\n",
    "    verbose=10\n",
    ")\n",
    "# Put data and labels in proper format\n",
    "data = train_data.iloc[:, :4].values\n",
    "labels = train_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "# Fit grid search object\n",
    "grid_search_cv.fit(data, labels)\n",
    "# Print and save results.\n",
    "print(\"XG Boost GridSearchCV best score = \" + str(grid_search_cv.best_score_))\n",
    "print(\"XG Boost GridSearchCV best parameters = \" + str(grid_search_cv.best_params_))\n",
    "predictions = grid_search_cv.predict(data)\n",
    "_, _, fscore, _ = precision_recall_fscore_support(predictions, labels)\n",
    "print(\"XG Boost GridSearchCV deceased class f1-score = \" + str(fscore[0]))\n",
    "accuracy = accuracy_score(predictions, labels)\n",
    "print(\"XG Boost GridSearchCV accuracy score = \" + str(accuracy))\n",
    "pd.DataFrame(grid_search_cv.cv_results_).to_csv(\"xgboost_results.csv\")\n",
    "xgb_model = grid_search_cv.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.755 total time=   4.5s\n",
      "[CV 2/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.352 total time=   1.9s\n",
      "[CV 3/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.188 total time=   1.5s\n",
      "[CV 4/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.191 total time=   0.9s\n",
      "[CV 5/5; 1/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 1/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.723 total time=   2.0s\n",
      "[CV 1/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.772 total time=   4.4s\n",
      "[CV 2/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.775 total time=   3.9s\n",
      "[CV 3/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.752 total time=   6.9s\n",
      "[CV 4/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.774 total time=   7.9s\n",
      "[CV 5/5; 2/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.774 total time=  10.0s\n",
      "[CV 1/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.543 total time=   9.4s\n",
      "[CV 2/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.760 total time=  10.0s\n",
      "[CV 3/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 3/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.754 total time=   9.9s\n",
      "[CV 4/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.571 total time=   9.1s\n",
      "[CV 5/5; 3/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.763 total time=   9.4s\n",
      "[CV 1/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.774 total time=  10.1s\n",
      "[CV 2/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.769 total time=   8.4s\n",
      "[CV 3/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.752 total time=   4.8s\n",
      "[CV 4/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.776 total time=   7.2s\n",
      "[CV 5/5; 4/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 4/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.764 total time=   3.8s\n",
      "[CV 1/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.767 total time=   5.2s\n",
      "[CV 2/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.709 total time=   1.9s\n",
      "[CV 3/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.728 total time=   4.7s\n",
      "[CV 4/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.612 total time=   3.7s\n",
      "[CV 5/5; 5/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 5/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.751 total time=   3.0s\n",
      "[CV 1/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.776 total time=   2.9s\n",
      "[CV 2/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.773 total time=   3.0s\n",
      "[CV 3/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.755 total time=   3.0s\n",
      "[CV 4/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.778 total time=   2.9s\n",
      "[CV 5/5; 6/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 6/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.767 total time=   3.0s\n",
      "[CV 1/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 1/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.757 total time=   5.1s\n",
      "[CV 2/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 2/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.771 total time=   5.2s\n",
      "[CV 3/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.751 total time=   5.1s\n",
      "[CV 4/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.661 total time=   5.3s\n",
      "[CV 5/5; 7/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.743 total time=   5.3s\n",
      "[CV 1/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.772 total time=   4.5s\n",
      "[CV 2/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.774 total time=   5.5s\n",
      "[CV 3/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.752 total time=   2.7s\n",
      "[CV 4/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.778 total time=   4.2s\n",
      "[CV 5/5; 8/32] START activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 8/32] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.766 total time=   3.0s\n",
      "[CV 1/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.528 total time=   2.5s\n",
      "[CV 2/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.764 total time=   4.2s\n",
      "[CV 3/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.419 total time=   0.9s\n",
      "[CV 4/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.765 total time=   6.3s\n",
      "[CV 5/5; 9/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 9/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.450 total time=   0.6s\n",
      "[CV 1/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.771 total time=   5.6s\n",
      "[CV 2/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.761 total time=   7.6s\n",
      "[CV 3/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.755 total time=   7.5s\n",
      "[CV 4/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.773 total time=   4.9s\n",
      "[CV 5/5; 10/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 10/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.767 total time=   4.4s\n",
      "[CV 1/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.586 total time=   9.1s\n",
      "[CV 2/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.683 total time=   9.2s\n",
      "[CV 3/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.719 total time=   9.1s\n",
      "[CV 4/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.760 total time=   9.1s\n",
      "[CV 5/5; 11/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 5/5; 11/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.762 total time=   7.7s\n",
      "[CV 1/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.773 total time=   6.0s\n",
      "[CV 2/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.769 total time=   3.7s\n",
      "[CV 3/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.753 total time=   4.8s\n",
      "[CV 4/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.776 total time=   2.4s\n",
      "[CV 5/5; 12/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 12/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.768 total time=   8.1s\n",
      "[CV 1/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.735 total time=   5.0s\n",
      "[CV 2/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.767 total time=   3.1s\n",
      "[CV 3/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.728 total time=   3.2s\n",
      "[CV 4/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.735 total time=   3.7s\n",
      "[CV 5/5; 13/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 13/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.584 total time=   4.4s\n",
      "[CV 1/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.771 total time=   2.1s\n",
      "[CV 2/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.774 total time=   3.7s\n",
      "[CV 3/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.753 total time=   2.3s\n",
      "[CV 4/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.773 total time=   4.8s\n",
      "[CV 5/5; 14/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 14/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.767 total time=   3.3s\n",
      "[CV 1/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.762 total time=   5.0s\n",
      "[CV 2/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.768 total time=   5.0s\n",
      "[CV 3/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 3/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.746 total time=   4.5s\n",
      "[CV 4/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.770 total time=   5.2s\n",
      "[CV 5/5; 15/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 5/5; 15/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.765 total time=   4.9s\n",
      "[CV 1/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.772 total time=   3.3s\n",
      "[CV 2/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.773 total time=   3.5s\n",
      "[CV 3/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.756 total time=   4.4s\n",
      "[CV 4/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.777 total time=   3.6s\n",
      "[CV 5/5; 16/32] START activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 16/32] END activation=tanh, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.766 total time=   3.0s\n",
      "[CV 1/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.745 total time=   4.9s\n",
      "[CV 2/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.766 total time=   7.6s\n",
      "[CV 3/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.756 total time=   2.2s\n",
      "[CV 4/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.766 total time=   4.1s\n",
      "[CV 5/5; 17/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 17/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.666 total time=   5.4s\n",
      "[CV 1/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.775 total time=   4.2s\n",
      "[CV 2/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.768 total time=   5.5s\n",
      "[CV 3/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.754 total time=   5.0s\n",
      "[CV 4/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.781 total time=   6.1s\n",
      "[CV 5/5; 18/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 18/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.764 total time=   3.7s\n",
      "[CV 1/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.768 total time=   7.7s\n",
      "[CV 2/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 2/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.773 total time=   7.6s\n",
      "[CV 3/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.751 total time=   7.6s\n",
      "[CV 4/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.772 total time=   7.7s\n",
      "[CV 5/5; 19/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n",
      "[CV 5/5; 19/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.763 total time=   7.2s\n",
      "[CV 1/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.769 total time=   3.3s\n",
      "[CV 2/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.777 total time=   3.7s\n",
      "[CV 3/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.740 total time=   3.6s\n",
      "[CV 4/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.769 total time=   1.7s\n",
      "[CV 5/5; 20/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 20/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.757 total time=   3.2s\n",
      "[CV 1/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.763 total time=   2.5s\n",
      "[CV 2/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.681 total time=   1.9s\n",
      "[CV 3/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.689 total time=   3.1s\n",
      "[CV 4/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.657 total time=   3.2s\n",
      "[CV 5/5; 21/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 21/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.724 total time=   1.9s\n",
      "[CV 1/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.765 total time=   2.0s\n",
      "[CV 2/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.753 total time=   2.5s\n",
      "[CV 3/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.752 total time=   2.9s\n",
      "[CV 4/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.777 total time=   2.2s\n",
      "[CV 5/5; 22/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 22/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.765 total time=   1.6s\n",
      "[CV 1/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.756 total time=   4.4s\n",
      "[CV 2/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.763 total time=   4.4s\n",
      "[CV 3/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.732 total time=   4.5s\n",
      "[CV 4/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 4/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.769 total time=   4.0s\n",
      "[CV 5/5; 23/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 5/5; 23/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.766 total time=   4.0s\n",
      "[CV 1/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.764 total time=   2.4s\n",
      "[CV 2/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.768 total time=   2.6s\n",
      "[CV 3/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.756 total time=   2.7s\n",
      "[CV 4/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.776 total time=   2.6s\n",
      "[CV 5/5; 24/32] START activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 24/32] END activation=relu, alpha=0.0001, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.767 total time=   3.7s\n",
      "[CV 1/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.745 total time=   5.7s\n",
      "[CV 2/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.752 total time=   6.0s\n",
      "[CV 3/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.748 total time=   7.3s\n",
      "[CV 4/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.766 total time=   5.6s\n",
      "[CV 5/5; 25/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 25/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=sgd;, score=0.728 total time=   4.9s\n",
      "[CV 1/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.740 total time=   1.8s\n",
      "[CV 2/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.769 total time=   2.2s\n",
      "[CV 3/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.741 total time=   2.0s\n",
      "[CV 4/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.774 total time=   3.9s\n",
      "[CV 5/5; 26/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 26/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=constant, solver=adam;, score=0.764 total time=   4.4s\n",
      "[CV 1/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.757 total time=   7.6s\n",
      "[CV 2/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.769 total time=   7.7s\n",
      "[CV 3/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.757 total time=   7.7s\n",
      "[CV 4/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.774 total time=   7.8s\n",
      "[CV 5/5; 27/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 27/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=sgd;, score=0.762 total time=   7.7s\n",
      "[CV 1/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.744 total time=   4.3s\n",
      "[CV 2/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.770 total time=   3.1s\n",
      "[CV 3/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.755 total time=   4.9s\n",
      "[CV 4/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.760 total time=   3.1s\n",
      "[CV 5/5; 28/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 28/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(10, 30, 10), learning_rate=adaptive, solver=adam;, score=0.763 total time=   1.7s\n",
      "[CV 1/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 1/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.702 total time=   2.6s\n",
      "[CV 2/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 2/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.719 total time=   1.8s\n",
      "[CV 3/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 3/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.723 total time=   1.8s\n",
      "[CV 4/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 4/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.749 total time=   2.9s\n",
      "[CV 5/5; 29/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd\n",
      "[CV 5/5; 29/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=sgd;, score=0.765 total time=   3.3s\n",
      "[CV 1/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 1/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.754 total time=   2.2s\n",
      "[CV 2/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 2/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.776 total time=   2.8s\n",
      "[CV 3/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 3/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.755 total time=   1.9s\n",
      "[CV 4/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 4/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.774 total time=   2.8s\n",
      "[CV 5/5; 30/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam\n",
      "[CV 5/5; 30/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=constant, solver=adam;, score=0.764 total time=   2.5s\n",
      "[CV 1/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.761 total time=   4.5s\n",
      "[CV 2/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.768 total time=   4.5s\n",
      "[CV 3/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.760 total time=   4.5s\n",
      "[CV 4/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n",
      "[CV 4/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.770 total time=   4.4s\n",
      "[CV 5/5; 31/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gatsby\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 31/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=sgd;, score=0.761 total time=   4.5s\n",
      "[CV 1/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.756 total time=   4.6s\n",
      "[CV 2/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.767 total time=   1.5s\n",
      "[CV 3/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.758 total time=   2.3s\n",
      "[CV 4/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.772 total time=   1.6s\n",
      "[CV 5/5; 32/32] START activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 32/32] END activation=relu, alpha=0.05, hidden_layer_sizes=(20,), learning_rate=adaptive, solver=adam;, score=0.764 total time=   1.7s\n",
      "MLP Classifier GridSearchCV best score = 0.7697394108725046\n",
      "MLP Classifier GridSearchCV best parameters = {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "MLP Classifier GridSearchCV deceased class f1-score = 0.6698872785829306\n",
      "MLP Classifier GridSearchCV accuracy score = 0.7766290468737128\n",
      "Training Dataset F1-Score = 0.7717864021821654\n",
      "Validation Dataset F1-Score = 0.7789981692891491\n"
     ]
    }
   ],
   "source": [
    "# Takes about 12 minutes to run.\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# x_train = train_data[['age', 'country', 'chronic_disease_binary', 'Case_Fatality_Ratio']]\n",
    "# y_train = train_data[['outcome_group']]\n",
    "mlp_gs = MLPClassifier()\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "data = train_data.iloc[:, :4].values\n",
    "labels = train_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=mlp_gs,\n",
    "    param_grid=parameter_space,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "grid_search_cv.fit(data,labels.ravel())\n",
    "\n",
    "print(\"MLP Classifier GridSearchCV best score = \" + str(grid_search_cv.best_score_))\n",
    "print(\"MLP Classifier GridSearchCV best parameters = \" + str(grid_search_cv.best_params_))\n",
    "predictions = grid_search_cv.predict(data)\n",
    "_, _, fscore, _ = precision_recall_fscore_support(predictions, labels)\n",
    "print(\"MLP Classifier GridSearchCV deceased class f1-score = \" + str(fscore[0]))\n",
    "accuracy = accuracy_score(predictions, labels)\n",
    "print(\"MLP Classifier GridSearchCV accuracy score = \" + str(accuracy))\n",
    "pd.DataFrame(grid_search_cv.cv_results_).to_csv(\"MLP Classifier_results.csv\")\n",
    "mlp_gs = grid_search_cv.best_estimator_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Check for overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset F1-Score = 0.820903438284191\n",
      "Validation Dataset F1-Score = 0.8177177668606479\n"
     ]
    }
   ],
   "source": [
    "# Checking for overfitting on XG Boost model by comparing results on train versus validation datasets.\n",
    "train_data_formatted = train_data.iloc[:, :4].values\n",
    "train_labels_truth = train_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "train_labels_predicted = xgb_model.predict(train_data_formatted)\n",
    "train_data_score = f1_score(train_labels_predicted, train_labels_truth, average = \"macro\")\n",
    "\n",
    "validation_data_formatted = validation_data.iloc[:, :4].values\n",
    "validation_labels_truth = validation_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "validation_labels_predicted = xgb_model.predict(validation_data_formatted)\n",
    "validation_data_score = f1_score(validation_labels_predicted, validation_labels_truth, average = \"macro\")\n",
    "\n",
    "print(\"Training Dataset F1-Score = \" + str(train_data_score))\n",
    "print(\"Validation Dataset F1-Score = \" + str(validation_data_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset F1-Score = 0.7717864021821654\n",
      "Validation Dataset F1-Score = 0.7789981692891491\n"
     ]
    }
   ],
   "source": [
    "train_data_formatted = train_data.iloc[:, :4].values\n",
    "train_labels_truth = train_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "train_labels_predicted = mlp_gs.predict(train_data_formatted)\n",
    "train_data_score = f1_score(train_labels_predicted, train_labels_truth, average = \"macro\")\n",
    "\n",
    "validation_data_formatted = validation_data.iloc[:, :4].values\n",
    "validation_labels_truth = validation_data.iloc[:, 4].values.reshape(-1, 1)\n",
    "validation_labels_predicted = mlp_gs.predict(validation_data_formatted)\n",
    "validation_data_score = f1_score(validation_labels_predicted, validation_labels_truth, average = \"macro\")\n",
    "\n",
    "print(\"Training Dataset F1-Score = \" + str(train_data_score))\n",
    "print(\"Validation Dataset F1-Score = \" + str(validation_data_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.7 Prediction on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# USING XG BOOST FOR NOW BUT WE CAN SUB THIS OUT FOR BEST PERFORMING MODEL LATER\n",
    "test_data = test_data.iloc[:, :4].values\n",
    "predicted_labels = xgb_model.predict(test_data)\n",
    "# CHANGE MODEL NAME TO BEST PERFORMING MODEL LATER\n",
    "model_name = \"xgboost\"\n",
    "result_data_frame = pd.DataFrame(test_data, columns=[\"age\", \"country\", \"chronic_disease_binary\", \"Case_Fatality_Ratio\"])\n",
    "\n",
    "# This function is from the TA\n",
    "def create_submission_file(y_preds, file_name):\n",
    "    with open(file_name, 'w') as csvfile:\n",
    "        wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow([\"Id\", \"Prediction\"])\n",
    "        for i, pred in enumerate(y_preds):\n",
    "            wr.writerow([str(i), str(pred)])\n",
    "create_submission_file(predicted_labels, \"submission_\"+model_name+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ebeb2db109b4e4030ca6b0eb886199afc2cd913864cd051a344632d0064a896"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
